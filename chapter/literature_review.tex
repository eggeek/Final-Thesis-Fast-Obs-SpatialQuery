\chapter{Literature Review}\label{lreview}
\section{Overview}\label{lroverview}
As we've mentioned in previous chapter, OkNN problem appears in both
AI path planning and Spatial query processing. Therefore, this literature review includes
related works in these two fields.

In section~\ref{lrai}, we introduce two classic pathfinding algorithms:
\textit{Dijkstra} and \textit{A*}, as the historic background.
In section~\ref{lrindex}, we introduce a spatial index \textit{R-tree},
and discuss how it solves traditional kNN problem.
In section~\ref{lrknn}, we focus on existing works on OkNN, two algorithms based on
\textit{Local Visibility Graph} will be discussed. 
In section~\ref{lrnav}, we introduce a very fast point-to-point algorithm in AI path planning
field which shows a new direction to solve OkNN problem.
In section~\ref{lrquery}, we briefly discuss other related spatial queries which can be
improved by our research.

\section{Classic pathfinding}\label{lrai}
The most widely used pathfinding algorithm is \textit{Dijkstra} \cite{dijkstra1959note}. 
The algorithm works on a nonnegative weighted graph, it requires a priority queue and
regards the length of shortest path as key, and it visit vertices in the order
of lenght of shortest path until requirements be satisfied, e.g. the target has been found.
When the target is the furthest vertex to the start vertex, \textit{Dijkstra} has to explore the entire
map. Based on such consideration, researchers generalized \textit{Dijkstra} algorithm to
\textit{best-first search} which explores a graph by expanding the most promising node chosen
acording to a specified rule.
\textit{A*} \cite{hart1968formal} is known as a famous \textit{best-first search},
it select the path that minimizes:
$$
f(n) = \textit{g-value}(n) + \textit{h-value}(n)
$$
where $n$ is the last node on the path, \textit{g-value} is the length of shortest path from start to
$n$, \textit{h-value} is a estimation of shortest path from $n$ to the goal which is
problem-specific. One important propert of \textit{h-value} is admissibility, meaning that it never
overestimates the actual cost to the target.
For example, in an Euclidean plane with obstacles, \textit{h-value} can be the Euclidean
distance.

In following sections and the chapter~\ref{proposedalgo}, we will show how \textit{Dijkstra} and
\textit{A*} algorithms be applied on the OkNN problem.

\section{Spatial Index}\label{lrindex}

\subsection{\textit{R-tree}}

\textit{R-tree} has many variations\cite{guttman1984r,beckmann1990r,sellis1987r+,kamel1993hilbert},
they improve efficiency in different aspects,
but they still provide same functionality,
so we only introduce the classic \textit{R-tree} in this section.

\begin{figure}[htp]
  \centering
  \includegraphics[width=.8\linewidth]{pic/mbr.PNG}
  \caption{\small Both segments, circle and irregular shape can be represented by their MBR}
  \label{mbr}
\end{figure}

\textit{R-tree} is a heighb-balanced tree \cite{guttman1984r}, all objects are stored in leaf
node. In leaf node, if an object is not a point, it would be represented by its \textit{Minimal Bounding
Rectangle} (MBR), figure~\ref{mbr} shows example of MBRs. Each interior node is also
represented by a MBR which contains either leaf nodes or descendant interior nodes.
To guarantee efficiency, each non-root node of \textit{R-tree} can contain at least $m$ entries
and at most $M$ entries, where $m, M$ are specified constant when \textit{R-tree} is built, and
\textit{R-tree}'s root alway has two entries. 
Usually, objects retrieval start from the root,
then narrow down to children nodes based on spatial information in their MBRs, and finally
retrieve objects from leaf nodes.
Figure~\ref{rtree} shows how to store and retrieve objects.

\begin{figure}[htp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\linewidth]{pic/hierarchy_mbr.PNG}
    \caption{Hierachy of MBRs}
    \label{hmbr}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\linewidth]{pic/rtree.PNG}
    \caption{Corresponding tree structure}
    \label{tree}
  \end{subfigure}
  \caption{\small $\{a,b,c,d,e,f,g,h\}$ is the object set,
  $R1,R2,R4,R5$ are leaf nodes, $R3,R6$ are interior nodes, and $R7$ is the root.
  The red oval is a range query, starting with $R7$, since $R6$'s MBR overlapped with query
  area, we narrow down to $R6$, then to $R5$, and finally retrieve $g$. Notice that $R3,R2$ also
  overlap with the query, so they will also be visited, but nothing retrieved.
  }
  \label{rtree}
\end{figure}

From the example in figure~\ref{rtree}, we can see that overlapping area will be explored
multiplel times in retrieval progress, which duplicated efforts.
Thus, some variants use strict non-overlapping interior node (e.g.
$R^+\textit{-tree}$\cite{sellis1987r+}), and non-overlapping \textit{R-tree} is a wide topic in
spatial index which beyond the scope of this thesis.

\subsection{Nearest Neighbor Query}
In the \textit{R-tree}, all nodes are organized by their spatial information,
so that the nearest neighbor of a point can be retrieved by exploring tree nodes in some order.
To introduce the algorithm, we need to discuss two metrics: given query point $q$ and the MBR of a tree node
\begin{itemize}
  \item \textit{\textbf{mindist}} is the minimal distance from $q$ to the MBR, it estimates the
    distance from $q$ to inside object, so this metric is the priority of the tree node;
  \item \textit{\textbf{minmaxdist}} is the uppber bound of the NN distance of any object inside
    the MBR, if the $mindist$ of any MBR large than this value, then such MBR cannot contains
    the nearest object, so this metric is for pruning.
\end{itemize}
The algorithm starts with root node and proceeds down the tree. When it visits a leaf node,
current nearest neighbor will be updated;
When it visits a non-leaf node, the children of such node is sorted by \textit{mindist}, and pruned by
\textit{minmaxdist}, then algorithm does \textit{depth-first-search} on ordered and pruned children nodes;
when algorithm finished, the updated nearest neighbor is the answer, and it can be easily
generalized to finding kNN by changes below:
\begin{itemize}
  \item  Tracking k current nearest neighbors, instead of one.
  \item  The pruning is according to the current k-th nearest neighbor.
\end{itemize}

This kind of algorithm is called \textit{branch-and-bound} traversal, which has been well
studied and widely used in other artifical intelligence areas\cite{sellis1987r+},
and existing NN queries are based on it with different ordering and pruning strategies,
more details are in \cite{roussopoulos1995nearest,cheung1998enhanced}.

\section{Obstacle k-Nearest Neighbor}\label{lrknn}

In OkNN problem, the metric is obstacle distance,
so all existing OkNN algorithms are actually Obstacle Distance Computation (ODC).
In following subsections, we introduce these ODC algorithms and show how to apply them on OkNN.

\subsection{In-main-memory OkNN}
Solving obstacle path problems in-main-memory has been well studied \cite{de2000computational},
these works need to compute visibility graph which any pair of co-visible vertices has en edge,
figure~\ref{vg} shows an example.
\begin{figure}[htp]
  \centering
  \begin{tikzpicture}[scale=0.8]
  %\includegraphics[width=.6\linewidth]{pic/vg.png}
    \input{./src/polyanya.tex}
    \drawboundary
    \drawobstacles
    \drawVG
  \end{tikzpicture}
  \caption{\small The rectangle is the boundary of the map, black polyogns are obstacles, and all
  black lines are edge in the visibility graph.}
  \label{vg}
\end{figure}

Since all edges of the shortest path belong to visibility graph \cite{lozano1979algorithm},
once precomputed it and include visible edges from query point, we can run shortest path
algorithm (e.g. \textit{Dijkstra}) to find k-nearest neighbor.
However, precomputing visibility graph(VG) is costly:
even the best algorithm \cite{ghosh1991output} has
$O(m + nlogn)$ runtime, where $n$ is the number of vertex and $m$ is the number edges,
and in practice $m$ can reach to $O(n^2)$.
In spatial database scenario, $n$ can be more than $10,000$, so in-main-memory approach is not
suitable for spatial database scenario.

\subsection{Local Visibility Graph}

Since building global VG is infeasible, researchers in spatial database field
are motivated to design an algorithm that only consider query related area.

In 2004, Zhang proposed the \textit{Local Visibility Graph} (LVG) algorithm\cite{zhang2004spatial}
to compute obstacle distance.
Assume obstacles are stored in \textit{R-tree},
given query point $q$, and a target $t$, the algorithm runs in
following way:
\begin{enumerate}
    \item It starts with a small VG centered on $q$ with radius $r=d_e(q, t)$ (figure~\ref{edbt1});
    \item Then compute shortest path on current VG (figure~\ref{edbt2});
    \item Enlarge the circle to current obstacle distance $r=d_o(q,t)$, update the VG
      incrementally (figure~\ref{edbt2}) and recompute the shortest path (figure~\ref{edbt4});
    \item Repeat the previous step until $r>=d_o(q, t)$.
\end{enumerate}

\begin{figure*}[!h]
  \begin{subfigure}{\linewidth}
    \centering
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc1.tex}
      \caption{
        \small 
        the long rectangle obstacle in the\\
        circle is retrieved and included in vg.
      }
      \label{edbt1}
    \end{subfigure}%
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc2.tex}
      \caption{
        \small current shortest path may be blocked by some obstacles outside
      }
      \label{edbt2}
    \end{subfigure}
  \end{subfigure}\par\medskip
  \begin{subfigure}{\linewidth}
    \centering
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc3.tex}
      \caption{
        \small enlarges the circle and updates the vg
      }
      \label{edbt3}
    \end{subfigure}%
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc4.tex}
      \caption{
        \small recomputes the shortest path  
      }
      \label{edbt4}
    \end{subfigure}
  \end{subfigure}
  \caption{\small LVG algorithm}
\end{figure*}

Since $r>=d_o(q, t)$, when algorithm finish, it guarantees that no obstacle on current shortest
path, and thus proof the correctness. This algorithm can be extended to multi-target
scenario to solve OkNN problem:
\begin{itemize}
  \item Initially, $t$ is the \textit{k-th} nearest neighbor in Euclidean space, so that it
    guarantees that the VG always contains at least $k$ targets;
  \item Terminate when $r$  not less than the current \textit{k-th} nearest distance;
\end{itemize}

\subsection{Fast filter}

There's another similar work proposed by Xia\cite{xia2004fast},
the difference is, instead of considering obstacles in a circle area,
it only retrieves obstacles on current shortest path,
updates the LVG and recomputes the shortest path.
Since less obstacles are involved in VG,
the algorithm is called \textit{Fast Filter}.
Figure~\ref{xia} shows an example.
\begin{figure*}[!h]
  \centering
  \begin{subfigure}{.45\linewidth}
    \centering
    \input{./src/fastfilter0.tex}
    \caption{}
    \label{xia0}
  \end{subfigure}%
  \begin{subfigure}{.45\linewidth}
    \centering
    \input{./src/fastfilter1.tex}
    \caption{}
    \label{xia1}
  \end{subfigure}
  \caption{
    \small Black polygons are obstacle,
    $q$ is query point, $t$ is the target.
    Initially, the VG only contains
    the rectangle obstacle between the $qt$,
    and the corresponding shortest path is computed (fig~\ref{xia0}).
    Then retrieves the square
    obstacle on the current path,
    updates VG and recomputes shortest path (fig~\ref{xia1}).
  }
  \label{xia}
\end{figure*}

To solve OkNN, we need following changes:
\begin{itemize}
  \item initially compute obstacle distance for k nearest neighbors, and store results in
    \textit{max-heap} with size $k$;
  \item keep retrieving next NN and compute the obstacle distance $d_o$;
  \item when $d_o$ not large than the top value of heap, pop top and insert the current $d_o$;
  \item terminate when the Euclidean distance to current NN is large than the Obstacle distance
    on top of the heap;
\end{itemize}
\subsection{Discussion}
\textit{LVG}\cite{zhang2004spatial} and \textit{Fast filter}\cite{xia2004fast} are simple to understand,
provide optimality guarantees and the promise of fast performance. Such advantages make them
attractive to researchers and, despite more than a decade since their introduction,
they continue to appear as ingredients in a variety of kNN studies from the literature; e.g.
\cite{gao2011efficient,gao2016reverse}.
However, these visibility graph based algorithms also suffer from a number of notable
disadvantages including:
\begin{enumerate}[label=(\roman*)]
  \item costly online visibility checks;
  \item an incremental construction process that has up to quadratic space and time complexity for the worst case;
  \item duplicated effort, since the graph is discarded each time the query point changes.
\end{enumerate}

\section{Pathfinding on Navigation Mesh}\label{lrnav}

\subsection{Historic background}
Because of the limitation of VG, \textit{Navigation Mesh} comes to our sight.
Ronald first proposed this concept in 1986\cite{ronald1986pathfinding}, then it is applied on
robotics and game pathfinding.

Navigation mesh divides traversable space into convex polygons,
figure~\ref{nav} shows an example.
Compare to VG (fig~\ref{vg}), it can be generated by\textit{Constrained Delaunay
Triangulation}\cite{chew1989constrained} in $O(nlogn)$ times,
so that it is feasible to preprocess the entire map.
Additionally, adding or removing obstacles only need to modify a few number of mesh polygons,
which is very flexible. It seems like a perfect framework for OkNN,
the only problem is: how to compute obstacle distance on it?

\begin{figure}[htp]
  \centering
  \begin{tikzpicture}[scale=0.8]
    \input{src/polyanya.tex}
    {
    \drawboundary
    \drawobstacles
    \drawmeshs
    }
  \end{tikzpicture}
  \caption{\small Navigation Mesh: The rectangle is the boundary of the map, black polyogns are
  obstacles, gray lines are edges of mesh polygons.}
  \label{nav}
\end{figure}

Previous pathfinding algorithms on navigation mesh are not suitable for spatial query
processing, and thus it's not attractive to researchers in this fields.
Three widly used algorithms are:
\begin{itemize}
\item Channel Search \cite{kallmann2005path}: first find an abstract path from start to target
    composed by polygons, then refine the abstract path to a sequence of concrete points. This
    algorithm only generate an approximately shortest path, the lack of optimality makes it not
    suitable for OkNN query.
  \item TA* \cite{demyen2006efficient}: similar to Channel Search, but it can repeat the search
    process until finding an optimal shortest path. The repeating is time-consuming, so it is not
    suitable for query processing.
  \item TRA* \cite{demyen2006efficient}: similar to TA*, but TRA* can utilize preprocessing to
    speed up pathfinding. The problem is that the precomputed information will be invalid when
    environment change, so it is not suitable for database scenario.
\end{itemize}

However, this fact has been changed by a recent work called
\textit{Polyanya}\cite{cuicompromise}. It is a fast, optimal and fexible pathfinding algorithm
which is perfect for query processing in spatial database.

\subsection{Polyanya}


\section{Related Spatial Queries}\label{lrquery}
