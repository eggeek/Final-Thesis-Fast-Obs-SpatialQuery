\chapter{Literature Review}\label{lreview}
\section{Overview}\label{lroverview}
OkNN problem appears in both AI path planning and Spatial query processing.
Therefore, in this chapter, the literature review includes related works in these two fields.

In section~\ref{lrai}, we introduce two classic pathfinding algorithms:
\textit{Dijkstra} and \textit{A*}, as the historical background.

In section~\ref{lrindex}, we introduce a spatial index \textit{R-tree},
and discuss how it solves traditional kNN problem.

In section~\ref{lrknn}, we focus on existing works on OkNN, two algorithms based on
\textit{Local Visibility Graph} will be discussed. 

In section~\ref{lrnav}, we introduce a very fast point-to-point algorithm in AI path planning
field which shows a new direction to solve OkNN problem.

In section~\ref{lrquery}, we briefly discuss other related spatial queries which can be
improved by our research.

\section{Classic pathfinding}\label{lrai}
The most widely used pathfinding algorithm is \textit{Dijkstra} \cite{dijkstra1959note}. 
The algorithm works on a nonnegative weighted graph, it requires a priority queue and
regards the length of shortest path as key, and it visit vertices in the order
of length of the shortest path until requirements are satisfied, e.g. the target has been found.
When the target is the furthest vertex to the start vertex, \textit{Dijkstra} has to explore the entire
map. Based on such consideration, researchers generalized \textit{Dijkstra} algorithm to
\textit{best-first search} which explores a graph by expanding the most promising node chosen
according to a specified rule.
\textit{A*} \cite{hart1968formal} is known as a famous \textit{best-first search},
it select the path that minimizes:
$$
f(n) = \textit{g-value}(n) + \textit{h-value}(n)
$$
where $n$ is the last node on the path, \textit{g-value} is the length of the shortest path from start to
$n$, \textit{h-value} is an estimation of the shortest path from $n$ to the goal which is
problem-specific. One important property of \textit{h-value} is admissibility, meaning that it never
overestimates the actual cost to the target.
For example, in an Euclidean plane with obstacles, \textit{h-value} can be the Euclidean
distance.

In following sections and the chapter~\ref{proposedalgo}, we will show how \textit{Dijkstra} and
\textit{A*} algorithms be applied on the OkNN problem.

\section{Spatial Index}\label{lrindex}

\subsection{\textit{R-tree}}

\textit{R-tree} has many variations\cite{guttman1984r,beckmann1990r,sellis1987r+,kamel1993hilbert},
they improve efficiency in different aspects,
but they still provide the same functionality,
so we only introduce the classic \textit{R-tree} in this section.

\begin{figure}[htp]
  \centering
  \includegraphics[width=.8\linewidth]{./pic/mbr.png}
  \caption{\small Both segments, circle and irregular shape can be represented by their MBR}
  \label{mbr}
\end{figure}

\textit{R-tree} is a heigh-balanced tree \cite{guttman1984r}, all objects are stored in a leaf
node. In leaf node, if an object is not a point, it would be represented by its \textit{Minimal Bounding
Rectangle} (MBR), figure~\ref{mbr} shows examples of MBR. Each interior node is also
represented by a MBR which contains either leaf nodes or descendant interior nodes.
To guarantee efficiency, each non-root node of \textit{R-tree} can contain at least $m$ entries
and at most $M$ entries, where $m, M$ are specified constant when \textit{R-tree} is built, and
\textit{R-tree}'s root always has two entries. 
Usually, objects retrieval start from the root,
then narrow down to children nodes based on spatial information in their MBRs, and finally
retrieve objects from leaf nodes.
Figure~\ref{rtree} shows how to store and retrieve objects.

\begin{figure}[htp]
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\linewidth]{./pic/hierarchy_mbr.png}
    \caption{Hierachy of MBRs}
    \label{hmbr}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=\linewidth]{./pic/rtree.png}
    \caption{Corresponding tree structure}
    \label{tree}
  \end{subfigure}
  \caption{\small $\{a,b,c,d,e,f,g,h\}$ is the object set,
  $R1,R2,R4,R5$ are leaf nodes, $R3,R6$ are interior nodes, and $R7$ is the root.
  The red oval is a range query, starting with $R7$, since $R6$'s MBR overlapped with query
  area, we narrow down to $R6$, then to $R5$, and finally retrieve $g$. Notice that $R3,R2$ also
  overlap with the query, so they will also be visited, but nothing retrieved.
  }
  \label{rtree}
\end{figure}

From the example in figure~\ref{rtree}, we can see that overlapping area will be explored
multiple times in retrieval progress, which duplicated efforts.
Thus, some variants use strict non-overlapping interior node (e.g.
$R^+\textit{-tree}$\cite{sellis1987r+}), and non-overlapping \textit{R-tree} is a wide topic in
the spatial index field which beyond the scope of this thesis.

\subsection{Nearest Neighbor Query}
In the \textit{R-tree}, all nodes are organized by their spatial information,
so that the nearest neighbor of a point can be retrieved by exploring tree nodes in some order.
To introduce the algorithm, we need to discuss two metrics: given query point $q$ and the MBR of a tree node
\begin{itemize}
  \item \textit{\textbf{mindist}} is the minimal distance from $q$ to the MBR, it estimates the
    distance from $q$ to inside object, so this metric is the priority of the tree node;
  \item \textit{\textbf{minmaxdist}} is the upper bound of the NN distance of any object inside
    the MBR, if the $mindist$ of any MBR large than this value, then such MBR cannot contains
    the nearest object, so this metric is for pruning.
\end{itemize}
The algorithm starts with root node and proceeds down the tree. When it visits a leaf node,
current nearest neighbor will be updated;
When it visits a non-leaf node, the children of such node is sorted by \textit{mindist}, and pruned by
\textit{minmaxdist}, then algorithm does \textit{depth-first-search} on ordered and pruned children nodes;
when algorithm finished, the updated nearest neighbor is the answer, and it can be easily
generalized to finding kNN by changes below:
\begin{itemize}
  \item  Tracking k current nearest neighbors, instead of one.
  \item  The pruning is according to the current k-th nearest neighbor.
\end{itemize}

This kind of algorithm is called \textit{branch-and-bound} traversal, which has been well
studied and widely used in other artificial intelligence areas\cite{sellis1987r+},
and most existing NN queries are based on it with different ordering and pruning strategies,
more details are in \cite{roussopoulos1995nearest,cheung1998enhanced}.

\section{Obstacle k-Nearest Neighbor}\label{lrknn}

In OkNN problem, the metric is obstacle distance,
so all existing OkNN algorithms are actually Obstacle Distance Computation (ODC).
In following subsections, we introduce these ODC algorithms and show how to apply them on OkNN.

\subsection{In-main-memory OkNN}
Solving obstacle path problems in-main-memory has been well studied \cite{de2000computational},
these works need to compute visibility graph which any pair of co-visible vertices has an edge,
figure~\ref{vg} shows an example.
\begin{figure}[htp]
  \centering
  \begin{tikzpicture}[scale=0.8]
  %\includegraphics[width=.6\linewidth]{pic/vg.png}
    \input{./src/polyanya.tex}
    \drawboundary
    \drawobstacles
    \drawVG
  \end{tikzpicture}
  \caption{\small The rectangle is the boundary of the map, black polygons are obstacles and all
  black lines are edges in the visibility graph.}
  \label{vg}
\end{figure}

Since all edges of the shortest path belong to visibility graph \cite{lozano1979algorithm},
once precomputed it and include visible edges from query point, we can run shortest path
algorithm (e.g. \textit{Dijkstra}) to find k-nearest neighbor.
However, precomputing visibility graph(VG) is costly:
even the best algorithm \cite{ghosh1991output} has
$O(m + nlogn)$ runtime, where $n$ is the number of vertexes and $m$ is the number of edges,
and in practice, $m$ can reach to $O(n^2)$.
In spatial database scenario, $n$ can be more than $10,000$, so in-main-memory approach is not
suitable for spatial database scenario.

\subsection{Local Visibility Graph}

Since building global VG is infeasible, researchers in spatial database field
are motivated to design an algorithm that only considers query related area.

In 2004, Zhang proposed the \textit{Local Visibility Graph} (LVG) algorithm\cite{zhang2004spatial}
to compute obstacle distance.
Assume obstacles are stored in \textit{R-tree},
given query point $q$, and a target $t$, the algorithm runs in
following steps:
\begin{enumerate}
    \item It starts with a small VG centered on $q$ with radius $r=d_e(q, t)$ (figure~\ref{edbt1});
    \item Then compute shortest path on the current VG (figure~\ref{edbt2});
    \item Enlarge the circle to current obstacle distance $r=d_o(q,t)$, update the VG
      incrementally (figure~\ref{edbt2}) and recompute the shortest path (figure~\ref{edbt4});
    \item Repeat the previous step until $r>=d_o(q, t)$.
\end{enumerate}

\begin{figure*}[!h]
  \begin{subfigure}{\linewidth}
    \centering
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc1.tex}
      \caption{
        \small 
        the long rectangle obstacle in the\\
        circle is retrieved and included in vg.
      }
      \label{edbt1}
    \end{subfigure}%
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc2.tex}
      \caption{
        \small current shortest path may be blocked by some obstacles outside
      }
      \label{edbt2}
    \end{subfigure}
  \end{subfigure}\par\medskip
  \begin{subfigure}{\linewidth}
    \centering
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc3.tex}
      \caption{
        \small enlarges the circle and updates the vg
      }
      \label{edbt3}
    \end{subfigure}%
    \begin{subfigure}{.45\linewidth}
      \centering
      \input{./src/edbt_odc4.tex}
      \caption{
        \small recomputes the shortest path  
      }
      \label{edbt4}
    \end{subfigure}
  \end{subfigure}
  \caption{\small LVG algorithm}
\end{figure*}

When algorithm finish, since $r>=d_o(q, t)$, it guarantees that no obstacle on the current shortest
path, and thus proving the correctness. This algorithm can be extended to multi-target
scenario to solve OkNN problem:
\begin{itemize}
  \item Initially, $t$ is the \textit{k-th} nearest neighbor in Euclidean space, so that it
    guarantees that the VG always contains at least $k$ targets;
  \item Terminate when $r$  not less than the current \textit{k-th} nearest distance;
\end{itemize}

\subsection{Fast filter}

There's another similar work proposed by Xia\cite{xia2004fast},
the difference is, instead of considering obstacles in a circle area,
it only retrieves obstacles on the current shortest path,
updates the LVG and recomputes the shortest path.
Since fewer obstacles are involved in VG,
the algorithm is called \textit{Fast Filter}.
Figure~\ref{xia} shows an example.
\begin{figure*}[!h]
  \centering
  \begin{subfigure}{.45\linewidth}
    \centering
    \input{./src/fastfilter0.tex}
    \caption{}
    \label{xia0}
  \end{subfigure}%
  \begin{subfigure}{.45\linewidth}
    \centering
    \input{./src/fastfilter1.tex}
    \caption{}
    \label{xia1}
  \end{subfigure}
  \caption{
    \small Black polygons are obstacles,
    $q$ is query point, $t$ is the target.
    Initially, the VG only contains
    the rectangle obstacle between the $qt$,
    and the corresponding shortest path is computed (fig~\ref{xia0}).
    Then retrieves the square
    obstacle on the current path,
    updates VG and recomputes the shortest path (fig~\ref{xia1}).
  }
  \label{xia}
\end{figure*}

To solve OkNN, we need following changes:
\begin{itemize}
  \item initially compute obstacle distance for k nearest neighbors, and store results in
    \textit{max-heap} with size $k$;
  \item keep retrieving next NN and compute the obstacle distance $d_o$;
  \item when $d_o$ not large than the top value of heap, pop top and insert the current $d_o$;
  \item terminate when the Euclidean distance to current NN is large than the Obstacle distance
    on top of the heap;
\end{itemize}
\subsection{Discussion}
When search space is large (e.g. target is far from the query point), \textit{fast
filter}\cite{xia2004fast} is
more efficient because it only considers obstacles that might on the path, meanwhile
\textit{LVG}\cite{zhang2004spatial} will build visibility graph for a large area, which is slow. 
In a multi-target scenario, when $k$ is large, \textit{LVG}\cite{zhang2004spatial} is more efficient because
\textit{Dijkstra} is a natural single-source algorithm, meanwhile, each time \textit{fast
filter}\cite{xia2004fast} can
only compute the path for a single target, so that it duplicates effort for common prefixes of $k$
targets.

Both \textit{LVG}\cite{zhang2004spatial} and \textit{Fast filter}\cite{xia2004fast} are simple to understand,
provide optimality guarantees and the promise of fast performance. Such advantages make them
attractive to researchers and, despite more than a decade since their introduction,
they continue to appear as ingredients in a variety of kNN studies from the literature; e.g.
\cite{gao2011efficient,gao2016reverse}.
However, these visibility graph based algorithms also suffer from a number of notable
disadvantages including:
\begin{enumerate}[label=(\roman*)]
  \item costly online visibility checks;
  \item an incremental construction process that has up to quadratic space and time complexity for the worst case;
  \item duplicated efforts are unavoidable, since the graph is discarded each time the query point changes.
\end{enumerate}

\section{Pathfinding on Navigation Mesh}\label{lrnav}

\subsection{Historical background}
Because of the limitation of VG, \textit{Navigation Mesh} comes to our sight.
Ronald first proposed this concept in 1986\cite{ronald1986pathfinding}, then it is applied on
robotics and game pathfinding.

Navigation mesh divides traversable space into convex polygons, the convexity of mesh
guarantees that all insides points are co-visible so that it not needs visibility checking,
Figure~\ref{nav} shows an example.
Compare to VG (fig~\ref{vg}), it can be generated by\textit{Constrained Delaunay
Triangulation}\cite{chew1989constrained} in $O(nlogn)$ times,
so that it is feasible to preprocess the entire map.
Additionally, adding or removing obstacles only needs to modify a few numbers of mesh polygons,
which is very flexible. It seems like a perfect framework for OkNN,
the only problem is that how to compute obstacle distance on it.

\begin{figure}[htp]
  \centering
  \begin{tikzpicture}[scale=0.8]
    \input{src/polyanya.tex}
    {
    \drawboundary
    \drawobstacles
    \drawmeshs
    }
  \end{tikzpicture}
  \caption{\small Navigation Mesh: The rectangle is the boundary of the map, black polygons are
  obstacles, gray lines are edges of mesh polygons.}
  \label{nav}
\end{figure}

Previous pathfinding algorithms on navigation mesh are not suitable for spatial query
processing, and thus it's not attractive to researchers in this fields.
Three widely used algorithms are:
\begin{itemize}
\item Channel Search \cite{kallmann2005path}: first find an abstract path from start to target
    composed of polygons, then refine the abstract path to a sequence of concrete points. This
    algorithm only generate an approximately shortest path, the lack of optimality makes it not
    suitable for OkNN query.
  \item TA* \cite{demyen2006efficient}: similar to Channel Search, but it can repeat the search
    process until finding an optimal shortest path. The repeating is time-consuming, so it is not
    suitable for query processing.
  \item TRA* \cite{demyen2006efficient}: similar to TA*, but TRA* can utilize preprocessing to
    speed up pathfinding. The problem is that the precomputed information will be invalid when
    the environment change, so it is not suitable for database scenario.
\end{itemize}

However, this fact has been changed by a recent work called
\textit{Polyanya}\cite{cuicompromise}. It is a fast, optimal and flexible pathfinding algorithm
which is perfect for query processing in spatial database.

\subsection{Polyanya}
\textit{Polyanya} can be seen as an instance of \textit{A*}: it performs a best-first search
using an admissible heuristic function to prioritize nodes. The mechanical details are however
quite different, there are three key components:
\begin{itemize}
\item \textbf{Search Nodes}: Conventional  search algorithms proceed from one traversable point
  to the next. \textit{Polyanya}, by comparison, searches from one \textit{edge} of the
  navigation mesh to another. In this model, search nodes are tuples $(I, r)$ where each
  $I=[a,b]$ is a contiguous interval of points and $r$ is a distinguished point called the
  \textit{root}. Nodes are constructed such that each point $p \in I$ is visible from $r$.
  Meanwhile, $r$ itself corresponds to the last turning point on the path: from $q$ to any $p
  \in I$. Figure~\ref{snode} shows an example.

  \begin{figure}[htb]
    \centering
     %\includegraphics[width=.5\linewidth]{pic/snode.png}
    \input{./src/snode.tex}
    \caption{\small Search nodes in Polyanya. Notice that the interval $I = [a, b]$ is
    a contiguous subset of points drawn from an edge of the navigation mesh.
    The corresponding root point, $r$, is either the query point itself 
    or the vertex of an obstacle. Taken together they form the search node $(I, r)$.}
    \label{snode}
  \end{figure}

\item \textbf{Successors}: Successor nodes $(I', r')$ are generated by "pushing" the current
  interval $I$ away from its root $r$ and throught the interior of an adjacent and traversable
  polygon. A successor is said to be \textit{obervable} if each point $p' \in I'$ is visible
  from $r$. The successor node in this case is formed by the tuple $(I',r)$. By contrast, a
  successor is said to be \textit{non-observable} if the \textit{taut} (i.e. locally optimal)
  path from $r$ to each $p' \in I'$ must pass through one of the endpoints of current interval
  $I=[a,b]$. The successor node in this case is formed by the tuple $(I', r')$ with $r'$ as
  one of the points $a$ or $b$. Figure~\ref{suc} shows an example.
 
  Note that the target point is inserted in the open list as a special case
  (observable or non-observable) successor whenever the search reaches its 
  containing polygon.  The interval of this successor contains only the target.
  \begin{figure}[ht]
    \centering
    \begin{tikzpicture}
      \input{./src/polyanya.tex}
      \drawmap
      \fill[lightgray] (e)--(f)--(h)--(g)--(c);
      \draw[black,very thin, dashed] (q)--($(q)!6cm!(e)$);
      \draw[black,very thin, dashed] (q)--($(q)!6cm!(c)$);
      \draw[green, line width=3pt] (j)--(h);
      \draw[green, line width=3pt] (h)--(g);
      \draw[green, line width=3pt] (g)--(c);
      \draw[green, line width=5pt, dashed] (c)--(e);
      \draw[orange!50, line width=3pt] (j)--(h);
      \draw[orange!50, line width=3pt] (h)--(g);
      \draw[orange!50, line width=3pt] (g)--(c);
      \draw[cyan, line width=3pt] (e)--(f);
      \draw[cyan, line width=3pt] (f)--(j);
      \drawVs     
      \nodelabel{j}{below}
    \end{tikzpicture}
    %\includegraphics[width=.6\linewidth]{pic/suc.png}
    \caption{\small We expand the node $([e,c],q)$ which has
    $([c,g],q)$ and $[h, j], q$ as observable successors.
    In addition, the nodes $([e,f],e)$, $([f,j],e)$ are non-observable.
    All other potential successors can be safely pruned (more details in~\cite{cuicompromise}).}
    \label{suc}
  \end{figure}

\pagebreak
\item \textbf{Evaluation}: When prioritising nodes for expansion, \textit{Polyanya} makes use of an
  \textit{f-value} estimation function which bounds the length of the optimal path:
  from $q$, throught the current node (i.e. via some $p \in I$) and onto the target. There are
  three cases to consider which describe the relative positions of the target in relation to
  the current node. These are illustrated in Figure~\ref{ef}. The objective in each case is to
  choose the unique $p \in I$ that minimise the estimate. The three cases together are
  sufficient to guarantee that the estimator is admissible.

  \begin{figure}[htp]
    \centering
    \input{./src/ef.tex}
    \caption{\small
    Polyanya $f$-value estimator. The current node is $(I, r)$ with $I = [a, b]$ and
    each of $t_1, t_2, t_3$ are possible target locations.
    \textbf{Case 1}: the target is $t_1$. In this case the point $p \in I$ with minimum
    $f$-value is at the intersection of the interval $I$ and the line $r \rightarrow t_1$.
    \textbf{Case 2}: the target is $t_2$. In this case the $p \in I$ with minimum $f$-value
    is one of two endpoints of $I$. 
    \textbf{Case 3}: the target is $t_3$. In this case the $p \in I$ with minimum $f$-value
    is obtained by first mirroring $t_3$ through $[a, b]$ and applying Case 1 or Case 2
    to the mirrored point (here, $t_1$). Notice that in this case, simply $r$ to $t_3$
    doesn't give us the \textit{h-value}, based on definition, it must reach the interval
    first.
    }
  \label{ef}
  \end{figure}
\end{itemize}

Similar to \textit{A*}, \textit{Polyanya} terminates when the target is expanded or when the
open list is empty. Extending it to multi-target OkNN is not a trivial problem, we will discuss
this in chapter~\ref{proposedalgo}.

\section{Other Obstacle Spatial Queries}\label{lrquery}
Obstacle spatial query processing is a broad research area, and many existing works are still
based on visibility graph, in this section, we review those works which can get benefit from
the OkNN in our research. 

\begin{itemize}

\item \textbf{Obstacle Range Query}(OR): given the query point $q$ and a range $r$,
  it returns all targets which obstacle distance to $q$ are less or equal to $r$ \cite{zhang2004spatial}. 
To solve this by OkNN, we can let $k$ be infinite and terminate the algorithm when current
obstacle distance large than $r$.

\item \textbf{Obstacle Reverse k-Nearest Neighbor}(ORkNN): it is proposed in
2011\cite{gao2011efficient} for $k=1$, and be generalized to $k>1$ in
2016\cite{gao2016reverse}. ORkNN given query point $q$ and $k$, return a set of targets which
regards $q$ as its OkNN: $\{t | q \in OkNN(t, k)\}$. The query processing has two stages:
(i) \textit{search stage}: explore search space to get a set of candidates; (ii) \textit{refine
stage}: calls OkNN for each candidate, remove a candidate if $q$ is not its OkNN.
The first stage needs to compute obstacle distance to prune search space, and the second stage 
can directly get benefit from the improvement of OkNN.

\item \textbf{Continuous Obstacle k-Nearest Neighbor}(COkNN): it's proposed in
  2009\cite{gao2009continuous}, similar to OkNN, but the query becomes a segment.
  The algorithm first generates a list of "split" points, and reduce the problem to finding the
    OkNN for these points. It also needs to compute obstacle distance to prune search space.

\end{itemize}

\section{Summary}
In this chapter, we've reviewed works that are related to our research.
We firstly introduced the background knowledge by discussing $\textit{A}^*$ and
\textit{Dijkstra}. 
Then we discussed existing works basically from three fields: Spatial Index, Spatial Query Processing and AI Pathfinding.
The major finding is that, in OkNN problem, existing VG based algorithms are hard to improve,
so we are motivated to look for a new framework, meanwhile,
the new work in AI Pathfinding field shows us a new direction.
